{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Coronory Artery Disease Project\n",
    "## Exploratory analysis\n",
    "### Prediction of heart disease given 14 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis we use the Cleveland \"Coronary Artery Disease\" dataset found on the UCI Machine Learning Repository\n",
    "at the following location:\n",
    "\n",
    "<a href=https://archive.ics.uci.edu/ml/datasets/Heart+Disease>Heart Disease Dataset</a>\n",
    "\n",
    "The objective of the analysis is to use statistical learning to identify factors associated with Coronary Artery\n",
    "Disease as indicated by a coronary angiography interpreted by a Cardiologist.\n",
    "\n",
    "According to the paper by (Detrano et al., 1989) the data represents data collected for 303 patients referred for\n",
    "coronary angiography at the Cleveland Clinic between May 1981 and September 1984. The 13 independent/ features\n",
    "variables can be divided into 3 groups as follows:\n",
    "\n",
    "Routine evaluation (based on historical data):\n",
    "* ECG at rest\n",
    "* Serum Cholesterol\n",
    "* Fasting blood sugar\n",
    "\n",
    "Non-invasive test data (informed consent obtained for data as part of research protocol):\n",
    "* Exercise ECG\n",
    "    * ST-segment peak slope (upsloping, flat or downsloping)\n",
    "    * ST-segment depression\n",
    "* Excercise Thallium scintigraphy (fixed, reversible or none)\n",
    "* Cardiac fluoroscopy (number of vessels appeared to contain calcium)\n",
    "\n",
    "Other demographic and clinical variables (based on routine data):\n",
    "* Age\n",
    "* Sex\n",
    "* Chest pain type\n",
    "* Systolic blood pressure\n",
    "* ST-T-wave abnormality (T-wave abnormality)\n",
    "* Probably or definite ventricular hypertrophy (Este's criteria)\n",
    "\n",
    "The dependent/ response variable was the angiographic test result indicating a >50% diameter narrowing.\n",
    "\n",
    "Detrano et al created 352 logistic regression models based on different combinations of the previously discussed\n",
    "13 variables. Depending on information available in the test dataset one of these models was applied during model\n",
    "validation.\n",
    "\n",
    "Unfortunately the the paper by (Detrano et al., 1989) does not publish extensive model accuracy results such as:\n",
    "overall accuracy, C-Statistic, precision (positive predictive value), recall (sensitivity) or specificity. The\n",
    "model was however validated on various external datasets which is very important. The positive predictive value\n",
    "(precision) is reported for a range of probability cut-off points for the various test sets. The various data sets\n",
    "have widely varying prevalence (38% - 81%), and hence te positive predictive value likewise varies widely between the\n",
    "reported tests.\n",
    "\n",
    "From these results one can see that the model was capable of a Precision of approximately 75% for datasets closely\n",
    "matching the Cleveland dataset in terms of disease prevalence within the test set.\n",
    "\n",
    "We are going to replicate the analysis by performing a logistic regression and will perform a validation study to\n",
    "confirm results obtained by (Detrano et al., 1989) in terms of model accuracy. Furthermore we will do an analysis of\n",
    "significance of the various logistic regression features as means of classifying feature importance.\n",
    "\n",
    "Subsequent to this analysis we will use an ensemble model (Random Forest) to create feature importance classifications\n",
    "to validate the regression findings. We will also apply our learnings to a Neural Network, to assess performance on\n",
    "the smaller dataset i.e. after features selection has been applied.\n",
    "\n",
    "We aim to achieve this by following the Machine Learning pipeline approach of deploying a variety of ML techniques to\n",
    "build a predictive model and analyse its results. In the process we hope to gain valuable insights. The various steps\n",
    "in the process are as follows (not necessarily in this order):\n",
    "\n",
    "- Load data\n",
    "- Prepare data\n",
    "    - Clean data\n",
    "        - Missing values\n",
    "        - Outliers\n",
    "        - Erroneous values\n",
    "    - Explore data\n",
    "        - Exploratory descriptive analysis (EDA)\n",
    "        - Correlation analysis\n",
    "        - Variable cluster analysis\n",
    "    - Transform Data\n",
    "        - Engineer features\n",
    "        - Encode data\n",
    "        - Scale & normalise data\n",
    "        - Impute data\n",
    "        - Feature selection/ importance analysis\n",
    "- Build model\n",
    "    - Model selection\n",
    "    - Data sampling (validation strategy, imbalanced classification)\n",
    "    - Hyperparameter optimisation\n",
    "- Validate model\n",
    "    - Accuracy testing\n",
    "- Analysis of results\n",
    "    - Response curves\n",
    "    - Accuracy analysis\n",
    "    - Commentary\n",
    "\n",
    "Let us start the analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlinear_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LogisticRegression\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstatsmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msm\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmlxtend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExhaustiveFeatureSelector \u001B[38;5;28;01mas\u001B[39;00m EFS\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m export_graphviz\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from subprocess import call\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from src.visualization.visualize import plot_confusion_matrix, plot_roc_curve, plot_feature_importance, \\\n",
    "    plot_feature_importance_log, plot_feature_importance_dec, plotVar, plotAge, plotContinuous, plotCategorical\n",
    "from IPython.core.display import HTML as Center\n",
    "\n",
    "Center(\"\"\" <style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style> \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Load data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('../data/raw/processed.cleveland.data', header = None, names = ['age', 'sex', 'chest_pain_type', 'rest_blood_press', 'cholesterol',\n",
    "                'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate', 'exer_ind_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thallium_scint', 'ca_disease'], index_col=None,\n",
    "                 usecols = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], sep=',', skipinitialspace=True)\n",
    "df.head(20)\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {
    "data_dictionary2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset read from csv file has 303 rows and 14 columns.\n",
    "The data dictionary specified that 303 rows and 75 columns existed.\n",
    "We therefore have the same number of rows as the data dictionary, but 61 fewer columns...\n",
    "\n",
    "We were lucky that the data was already pre-processed, and this can be observed from the subset of data displayed\n",
    "appearing very clean. Hopefully not much further cleaning would be required.\n",
    "\n",
    "We created a data dictionary for the data is as follows:\n",
    "\n",
    "![data_dictionary2.png](attachment:data_dictionary2.png)\n",
    "\n",
    "The original field names were not very informative. We therefore renamed the fields based on information gathered\n",
    "from the article by Detrano et al.\n",
    "\n",
    "Let us explore the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Clean data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of data\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output we observe that we have twelve numeric columns and two \"object\" columns. The data dictionary\n",
    "however specifies that all fields are numeric. This means that Python could not convert two numeric variables\n",
    "(num_major_vessels and thallium_scint) to numeric columns due to their contents being non-numeric. Let us investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Find out what types of data is stored in object column. Use simple regex. Leading number omitted not catered for.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Future improvement.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m r \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39mcompile(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124md+[.,]\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124md*\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241m.\u001B[39mnum_major_vessels\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mbool\u001B[39m(r\u001B[38;5;241m.\u001B[39mmatch(x)))\u001B[38;5;241m.\u001B[39mvalue_counts()\n\u001B[1;32m      5\u001B[0m df\u001B[38;5;241m.\u001B[39mthallium_scint\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mbool\u001B[39m(r\u001B[38;5;241m.\u001B[39mmatch(x)))\u001B[38;5;241m.\u001B[39mvalue_counts()\n\u001B[1;32m      7\u001B[0m df\u001B[38;5;241m.\u001B[39mloc[df\u001B[38;5;241m.\u001B[39mnum_major_vessels\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mbool\u001B[39m(r\u001B[38;5;241m.\u001B[39mmatch(x))) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m]\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Find out what types of data is stored in object column. Use simple regex. Leading number omitted not catered for.\n",
    "# Future improvement.\n",
    "r = re.compile(r'\\d+[.,]\\d*')\n",
    "df.num_major_vessels.apply(lambda x: bool(r.match(x))).value_counts()\n",
    "df.thallium_scint.apply(lambda x: bool(r.match(x))).value_counts()\n",
    "\n",
    "df.loc[df.num_major_vessels.apply(lambda x: bool(r.match(x))) == False]\n",
    "df.loc[df.thallium_scint.apply(lambda x: bool(r.match(x))) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 4 non-numeric fields in num_major_vessels and 2 in thallium_scint. These values are all '?'.\n",
    "It is a reasonable assumption that these are missing values from data entry due to the placeholder. We will therefore\n",
    "clean the data by replacing these values with NaN and converting all character values to decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all non numeric data with NaN, convert strings to numbers.\n",
    "df_clean = df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if that worked! We should now have only decimal and null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of null values\n",
    "print(df_clean.isnull().sum())\n",
    "\n",
    "# Actual null values\n",
    "df_clean[df_clean.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great we have 6 null values, 4 in num_major_vessels and 2 in thallium_scint as expected. We can also observe\n",
    "that none of the other fields contain any null values. Seeing as there are only a handful of these values and none\n",
    "in the response variable, it is not necessary to remove these records from the dataset at this stage.\n",
    "\n",
    "We now have a dataset with 303 records and 14 numeric fields, as per the data dictionary, there are still 6 missing\n",
    "values in the 'num_major_vessels' and 'thallium_scint' fields though. Due to the low number of missing values and even\n",
    "distribution of values in these fields (see explore analysis below) we will now substitute these with median values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = df_clean.copy()\n",
    "median = df_fin['num_major_vessels'].median()\n",
    "df_fin['num_major_vessels'].fillna(median, inplace=True)\n",
    "print(\"Number of null values in num_major_vessels column: {}\".format(df_fin['num_major_vessels'].isnull().sum()))\n",
    "\n",
    "median = df_fin['thallium_scint'].median()\n",
    "df_fin['thallium_scint'].fillna(median, inplace=True)\n",
    "print(\"Number of null values in thallium_scint column: {}\".format(df_fin['thallium_scint'].isnull().sum()))\n",
    "print(\"Dataframe dimension: {}\".format(df_fin.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our set is finally ready for further analysis. We will now look at the distribution of variables and any possible\n",
    "outliers or heavy tailed distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Explore data</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by looking at the number of unique records per variable. We start here as variables with too little variability\n",
    "will be discarded from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mdf_fin\u001B[49m\u001B[38;5;241m.\u001B[39mnunique())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_fin' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_fin.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no columns with only one value. We therefore retain all columns for ML purposes as there is enough\n",
    "variability to warrant using the data. There are many variables with fewer than 10 levels which could be considered\n",
    "as categorical. Based on our initial assessment of the data we will work with levels of measurement for the data as\n",
    "follows:\n",
    "\n",
    "- age (continuous)\n",
    "- sex (binary)\n",
    "- chest_pain_type (ordinal)\n",
    "- rest_blood_press (continuous)\n",
    "- cholesterol (continuous)\n",
    "- fasting_blood_sugar (binary)\n",
    "- rest_ecg (ordinal)\n",
    "- max_heart_rate (continuous)\n",
    "- exer_ind_angina (binary)\n",
    "- st_depression (continuous)\n",
    "- st_slope (ordinal)\n",
    "- num_major_vessels (ordinal)\n",
    "- thallium_scint (ordinal - needs reordering)\n",
    "- ca_disease (binary - we will need to transform as there are actually 5 levels in the data)\n",
    "\n",
    "At this point it seems as if the only nominal data is binary, which means we might not need any One Hot Encoding\n",
    "initially. We will leave the ordinal data as is for the initial analysis.\n",
    "\n",
    "It is important to note the large number binary and ordinal variables which indicates that the original continuous\n",
    "variables have in all likelihood been discretised by the original authors. This could possibly be revisited at a later\n",
    "later stage by considering the original data.\n",
    "\n",
    "Next we look at the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now extract data according levels of measurement first to ease analysis. We also rename the variables to enable\n",
    "ease of interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract categorical variables for analysis.\n",
    "df_fin_cat = df_fin.copy()\n",
    "names_cat = ('sex', 'chest_pain_type', 'fasting_blood_sugar', 'rest_ecg', 'exer_ind_angina', 'st_slope',\n",
    "             'num_major_vessels', 'thallium_scint', 'ca_disease')\n",
    "df_fin_cat = df_fin_cat.loc[:, names_cat]\n",
    "\n",
    "# Extract continuous variables for analysis.\n",
    "#df_fin.reset_index(drop=True, inplace=True)\n",
    "df_fin_con = df_fin.copy()\n",
    "names_con = ('age', 'rest_blood_press', 'cholesterol', 'max_heart_rate', 'st_depression')\n",
    "df_fin_con = df_fin_con.loc[:, names_con]\n",
    "\n",
    "# Plotting label dictionary\n",
    "plot_cat = [('sex', ['female', 'male']),\n",
    "              ('chest_pain_type', ['typical angina', 'atypical angina', 'non-anginal pain', 'asymptomatic']),\n",
    "              ('fasting_blood_sugar', ['fbs > 120mg', 'fbs < 120mg']),\n",
    "              ('rest_ecg', ['normal', 'ST T-wave', 'left ventricular']),\n",
    "              ('exer_ind_angina', ['yes', 'no']),\n",
    "              ('st_slope', ['upsloping', 'flat', 'downsloping']),\n",
    "              ('num_major_vessels', ['0', '1', '2', '3']),\n",
    "              ('thallium_scint', ['normal', 'fixed defect', 'reversible defect']),\n",
    "              ('ca_disease', ['No CA disease', 'CA disease'])]\n",
    "plot_con = [('age', 'age in years'),\n",
    "            ('rest_blood_press', 'blood pressure in mm Hg'),\n",
    "              ('cholesterol', 'serum cholesterol in mg/d'),\n",
    "              ('max_heart_rate', 'maximum heart rate achieved'),\n",
    "              ('st_depression', 'ST depression by exercise relative to rest'),\n",
    "              ('ca_disease', 'Coronary Artery disease')]\n",
    "\n",
    "# Extract numeric variables for analysis.\n",
    "df_fin.reset_index(drop=True, inplace=True)\n",
    "df_fin_num = df_fin.copy()\n",
    "names_num = ('age', 'sex', 'chest_pain_type', 'rest_blood_press', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg',\n",
    "             'max_heart_rate', 'exer_ind_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thallium_scint',\n",
    "             'ca_disease')\n",
    "df_fin_num = df_fin_num.loc[:, names_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outcome_counts = df_fin_cat.groupby('ca_disease').size()\n",
    "outcome_counts = df_fin_cat['ca_disease'].value_counts()\n",
    "print(outcome_counts)\n",
    "\n",
    "# Plot outcome counts.\n",
    "ax = sns.barplot(x=outcome_counts.index, y=outcome_counts.values, alpha=0.9)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "#ax.title.set_size(45)\n",
    "ax.tick_params('y', labelsize = 20);\n",
    "ax.tick_params('x', labelsize = 20);\n",
    "plt.title('Frequency Distribution of Outcomes', fontsize=20)\n",
    "plt.ylabel('Number of Occurrences')\n",
    "plt.xlabel('Outcome')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread of the data is good for classification, as there are a large number of positive cases. If one combines\n",
    "classes 1, 2, 3 and 4 as suggested there will be a fairly even split between positive and negative outcomes. Let\n",
    "us confirm if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Transform y variable\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df_fin_cat[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_bin\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf_fin\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mca_disease\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      4\u001B[0m c \u001B[38;5;241m=\u001B[39m df_fin_cat\u001B[38;5;241m.\u001B[39mnum_bin\u001B[38;5;241m.\u001B[39mvalue_counts(dropna\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m      5\u001B[0m p \u001B[38;5;241m=\u001B[39m df_fin_cat\u001B[38;5;241m.\u001B[39mnum_bin\u001B[38;5;241m.\u001B[39mvalue_counts(dropna\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, normalize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_fin' is not defined"
     ]
    }
   ],
   "source": [
    "# Transform y variable\n",
    "df_fin_cat['num_bin'] = df_fin['ca_disease'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "c = df_fin_cat.num_bin.value_counts(dropna=False)\n",
    "p = df_fin_cat.num_bin.value_counts(dropna=False, normalize=True)\n",
    "output = pd.concat([c,p], axis=1, keys=['counts', '%'])\n",
    "print(output)\n",
    "\n",
    "ax = sns.barplot(x=p.index, y=p.values)\n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "#ax.title.set_size(45)\n",
    "ax.tick_params('y', labelsize = 20);\n",
    "ax.tick_params('x', labelsize = 20);\n",
    "plt.title('Frequency Distribution of Outcomes', fontsize = 20)\n",
    "plt.ylabel('Number of Occurrences')\n",
    "plt.xlabel('Outcome')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the distribution of positive and negative values is balanced with 46% of values denoting a positive\n",
    "outcome. It is therefore very unlikely that we would need to make allowance for imbalanced classes (by resampling,\n",
    "boosting or using an alternative ML algorithm such as Boosting) as there is a sufficiently large proportion of\n",
    "positive outcomes. The sample size of this dataset is however very small i.e. 303, so we will revisit this assumption\n",
    "once we have done some accuracy testing.\n",
    "\n",
    "Let us consider the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class level counts for categorical variables.\n",
    "for variable in names_cat:\n",
    "    print(df_fin_cat[variable].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart plot of categorical variables.\n",
    "fig, ax = plt.subplots(3, 3, figsize=(25, 20));\n",
    "for variable, subplot in zip(names_cat, ax.flatten()):\n",
    "    subplot.xaxis.label.set_size(34)\n",
    "    subplot.yaxis.label.set_size(34)\n",
    "    subplot.tick_params('y', labelsize = 30);\n",
    "    subplot.tick_params('x', labelsize = 30);\n",
    "    cp = sns.countplot(x=df_fin_cat[variable], ax=subplot);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks fine from a modelling perspective as there are no variables with empty classes. We picked up from the\n",
    "data dictionary that the 'thallium_scint' variable needs to be recoded due to incorrect labelling i.e. the order\n",
    "does not result in an increasing ordinal value.\n",
    "\n",
    "It is interesting to note that there are ~30% females and ~60% males. The distribution of chest pain also seems\n",
    "increase in a linear fashion for this population, with the largest portion of the population suffering from severe\n",
    "chest pain.\n",
    "\n",
    "Next, let us consider the continuous variables. We start by looking at age patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous density plot\n",
    "df_fin_num['ca_disease'] = df_fin_num['ca_disease'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "fig_age, axes = plt.subplots(nrows=1, ncols=1, figsize=(10, 6), squeeze=False)\n",
    "_ = plotAge(df=df_fin_num, axes=axes, single_plot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that individuals suffering from coronary artery disease have a higher average age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 number summary.\n",
    "df_fin_con.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous density plot\n",
    "#df_fin_num['ca_disease'] = df_fin_num['ca_disease'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "fig_continuous, axes = plt.subplots(nrows=len(plot_con)-1, ncols=2, figsize=(15, 22))\n",
    "_ = plotVar(isCategorical=False, categorical = plot_cat, continuous = plot_con, df=df_fin_num, axes=axes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violin plots demonstrate that the distributions for age, maximum HR and ST depression differ between individuals\n",
    "with and those without ca disease, whereas there is little difference in the distributions for resting BP and\n",
    "cholesterol.\n",
    "\n",
    "The violin plot for age against coronary artery disease demonstrates that the age of individuals without ca disease is\n",
    "evenly spread between the ages of 40 and 65, with some younger patients below the age of 30, whereas individuals with\n",
    "ca disease are mostly older, with a median age of approx 60 and few, if any, below 30 years of age.\n",
    "\n",
    "The median maximum HR for individuals without ca disease is higher (\\~160) than for individuals with ca disease (\\~150),\n",
    "with a narrower distribution around the mean, whereas individuals with ca disease have a skewed distribution towards\n",
    "lower maximum HR, with a larger proportion having max HR below 100 than healthy individuals.\n",
    "\n",
    "The distribution for ST depression is starkly different, with individuals without ca disease having a median ST\n",
    "depression of 0, with a narrow distribution around the mean, and a small proportion having ST depression between 1 and 2.\n",
    "\n",
    "In contrast, individuals with ca disease follow a broader distribution around a median of ~1.5, with a substantial\n",
    "proportion of individuals with ST depression >2. Resting blood pressure and cholesterol do not appear to be\n",
    "significantly different between patients with and without ca disease, with both groups having similar median resting\n",
    "BP (around 125mmHg) and cholesterol (200-250) and roughly even spread around the point estimates. A small number of\n",
    "individuals with ca disease have much higher resting BP of >200, whereas none of those without ca disease have a\n",
    "resting BP >200. However, this may not be statistically significant. Interestingly, some individuals without ca disease\n",
    "have very high cholesterol (500-600).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names_con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m variable \u001B[38;5;129;01min\u001B[39;00m \u001B[43mnames_con\u001B[49m:\n\u001B[1;32m      2\u001B[0m     skew \u001B[38;5;241m=\u001B[39m df_fin_con[variable]\u001B[38;5;241m.\u001B[39mskew()\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSkewness value for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(variable, skew))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'names_con' is not defined"
     ]
    }
   ],
   "source": [
    "for variable in names_con:\n",
    "    skew = df_fin_con[variable].skew()\n",
    "    print(\"Skewness value for {}: {}\".format(variable, skew))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of continuous variables\n",
    "medianprops = {'color': 'magenta', 'linewidth': 2}\n",
    "boxprops = {'color': 'black', 'linestyle': '-', 'linewidth': 4}\n",
    "whiskerprops = {'color': 'black', 'linestyle': '-', 'linewidth': 4}\n",
    "capprops = {'color': 'black', 'linestyle': '-', 'linewidth': 4}\n",
    "flierprops = {'color': 'black', 'marker': 'x', 'markersize': 25}\n",
    "\n",
    "_ = df_fin_con.plot(kind='box', subplots=True, figsize=(35, 25), layout=(2,3), fontsize = 50, medianprops=medianprops,\n",
    "                    boxprops=boxprops, whiskerprops=whiskerprops, capprops=capprops, flierprops=flierprops);\n",
    "\n",
    "_ = plt.tight_layout();\n",
    "_ = plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar observations to those made for the density and violin plots. We are dealing with an older population here\n",
    "with average age of 54 years old. There are a few outliers for high resting blood pressure with the distribution\n",
    "showing a slight skew to the right. Likewise for cholesterol and st_depression, with these two showing even higher\n",
    "skewness. Conversely max_heart_rate has outliers to left and slight skewness to left too. This makes sense,\n",
    "as higher values for the prior could indicate poorer health, whereas lower values for max_heart_rate could indicate\n",
    "poorer health, as observed in the violin plots.\n",
    "\n",
    "The distributions of the feature variables have varying scales, so standardisation would be required for ML purposes.\n",
    "For regression, normalisation might improve outcomes (for this investigation we will however not perform normalisatoin).\n",
    "Investigation into outliers is recommended as it might reveal interesting facts and would improve the model performance\n",
    "if outliers were addressed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Build Naive Model - Baseline</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first objective is to obtain a baseline measure of the strength of association between all the variables and the\n",
    "outcome. For this, we will build a basic Logistic Regression model, without transforming or scaling any of the\n",
    "variables.\n",
    "\n",
    "We start by splitting the response and the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y variable\n",
    "df_fin['ca_disease'] = df_fin['ca_disease'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Copy original dataset\n",
    "df_fin_nn = df_fin.copy()\n",
    "\n",
    "# Group response values to form binary response\n",
    "y = df_fin_nn.loc[:, 'ca_disease']\n",
    "\n",
    "# Split data into features (X) and response (y)\n",
    "X = df_fin_nn.loc[:, ('age', 'sex', 'chest_pain_type', 'rest_blood_press', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate', 'exer_ind_angina', 'st_depression', 'st_slope',\n",
    "                   'num_major_vessels', 'thallium_scint')]\n",
    "\n",
    "X.head()\n",
    "\n",
    "# Put the response y into an array\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_train_init, X_test_init, y_train_init, y_test_init \u001B[38;5;241m=\u001B[39m train_test_split(\u001B[43mX\u001B[49m, y, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_init, X_test_init, y_train_init, y_test_init = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage holdout data: {}%'.format(round(100*(len(X_test_init)/len(X)),0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build and test a naive logistic regression model - without any transformations or optimisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial model\n",
    "logreg = LogisticRegression(max_iter=2000000, fit_intercept = False)\n",
    "\n",
    "# Probability scores for test set\n",
    "y_score_init = logreg.fit(X_train_init, y_train_init).decision_function(X_test_init)\n",
    "\n",
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test_init, y_score_init)\n",
    "\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test_init)\n",
    "# Accuracy before model parameter optimisation\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test_init)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the accuracy measurements the baseline model performs very well. A C-statistic of 87% on data that\n",
    "has not been scaled or transformed is a very good result. This result confirms our EDA outcomes which showed\n",
    "correlation between age and the continuous variables and the outcome variable. Based on this result it is evident\n",
    "that this correlation is strong for at least a few of the variables.\n",
    "\n",
    "We will now investigate this correlation further, but first, we will transform and scale the variables to see whether\n",
    "we can improve the accuracy obtained by the naive modelling approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Build Logistic Regression - Release 1</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now scale and transform variables to obtain a very basic improvement on the naive model. We will not perform\n",
    "extensive feature engineering or advanced hyper-parameter tuning at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [13]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Transform thallium_scint variable\u001B[39;00m\n\u001B[1;32m      2\u001B[0m trans_thal \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m3\u001B[39m:\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m7\u001B[39m:\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m6\u001B[39m:\u001B[38;5;241m2\u001B[39m}\n\u001B[0;32m----> 3\u001B[0m df_fin_nn \u001B[38;5;241m=\u001B[39m \u001B[43mdf_fin\u001B[49m\u001B[38;5;241m.\u001B[39mreplace({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthallium_scint\u001B[39m\u001B[38;5;124m\"\u001B[39m: trans_thal})\n\u001B[1;32m      4\u001B[0m feature_names \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msex\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchest_pain_type\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrest_blood_press\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcholesterol\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfasting_blood_sugar\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrest_ecg\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m                  \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_heart_rate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexer_ind_angina\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mst_depression\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mst_slope\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_major_vessels\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthallium_scint\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Re-extract transformed X features\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_fin' is not defined"
     ]
    }
   ],
   "source": [
    "# Transform thallium_scint variable\n",
    "trans_thal = {3:0, 7:1, 6:2}\n",
    "df_fin_nn = df_fin.replace({\"thallium_scint\": trans_thal})\n",
    "feature_names = ('age', 'sex', 'chest_pain_type', 'rest_blood_press', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg',\n",
    "                 'max_heart_rate', 'exer_ind_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thallium_scint')\n",
    "\n",
    "# Re-extract transformed X features\n",
    "X = df_fin_nn.loc[:, feature_names]\n",
    "\n",
    "# Rebuild training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Create variables for Random Forest model\n",
    "X_train_rf = X_train.copy()\n",
    "X_test_rf = X_test.copy()\n",
    "y_train_rf = y_train.copy()\n",
    "y_test_rf = y_test.copy()\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data set\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Apply to test data\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a logistic regression model with data scaled and transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial model\n",
    "logreg = LogisticRegression(fit_intercept = False)\n",
    "\n",
    "# Probability scores for test set\n",
    "y_score = logreg.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "# Accuracy before model parameter optimisation\n",
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scaling and transforming the data, we observe a modest improvement in the accuracy of the model. Although\n",
    "accuracy in itself probably does not warrant the transformation and scaling, model performance in terms of\n",
    "convergence has improved by an order of magnitude as number of iterations required before convergence was previously\n",
    "larger than 1000,000 and after the data has been scaled number of iterations reduced to less than 100,0000.\n",
    "This is an encouraging result as it shows the model now captures the signal in the data without the need for excessive\n",
    "computation which will allow us to use more complex models to improve accuracy.\n",
    "\n",
    "The objective of this study is however not to maximise accuracy, but to find correlation between predictors and the\n",
    "response. Therefore we turn our attention now to study variable correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Build Logistic Regression - Release 2</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now perform feature selection in order to ascertain whether a smaller parsimonious model could be built with fewer\n",
    "variables. As per the article by (Detrano et al., 1989) this could be useful from a practical perspective as not all\n",
    "healthcare settings have all the variables to their disposal which necessitates the deployment of several complex\n",
    "predictive models which is not practical from an operational perspective.\n",
    "\n",
    "We will first perform correlation and regression tests on the data. These tests are best performed by considering\n",
    "continuous and categoric variables separately due to the intrinsic difference in regression coefficient values\n",
    "for these variables. We will then perform a few numeric methods on the full dataset and compare results.\n",
    "\n",
    "We start by considering the continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fin_con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Pearson correlation plot.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m correlations \u001B[38;5;241m=\u001B[39m \u001B[43mdf_fin_con\u001B[49m\u001B[38;5;241m.\u001B[39mcorr()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Plot correlation matrix\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#sns.set(font_scale=1);\u001B[39;00m\n\u001B[1;32m      5\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m15\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_fin_con' is not defined"
     ]
    }
   ],
   "source": [
    "# Pearson correlation plot.\n",
    "correlations = df_fin_con.corr()\n",
    "# Plot correlation matrix\n",
    "#sns.set(font_scale=1);\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = sns.heatmap(correlations, annot=True, linewidths = 0, vmin=-.5, cmap='pink_r')\n",
    "ax.xaxis.label.set_size(15)\n",
    "ax.yaxis.label.set_size(15)\n",
    "#ax.title.set_size(45)\n",
    "ax.tick_params('y', labelsize = 15, labelrotation=0);\n",
    "ax.tick_params('x', labelsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a very strong inverse correlation between maximum heart rate and age. This makes sense as one's\n",
    "maximum heart typically decreases with age. Similarly there is a strong inverse correlation between max_heart_rate and\n",
    "st_depression. This makes sense as a lower max_heart_rate is likely to indicate poorer health and could therefore be\n",
    "correlated with a greater st_depression.\n",
    "\n",
    "We also see that there is a strong positive correlation between maximum heart rate and both cholesterol and resting\n",
    "blood pressure. High blood pressure and cholesterol are typically indications of poor health which would result\n",
    "in lower maximum heart rate.\n",
    "\n",
    "Another observation of interest is the strong correlation between cholesterol and age. These variables could make\n",
    "strong combined predictors for a next iteration of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method we use is to compare the relative importance of feature variables is that of Logistic Regression.\n",
    "We will consider the regression coefficient values for all our continuous variables. Scikit-learn does not\n",
    "implement feature importance measures for logistic regression. We therefore make use of the statsmodel libraries\n",
    "implementation. There is no option for a Univariate test, so we will first perform a multivariate analysis.\n",
    "We will thereafter make use of the mlextend library to perform a Univariate Logistic Regression test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract continuous and categorical variables for analysis.\n",
    "X_con = df_fin_con.copy()\n",
    "X_cat = df_fin_cat.loc[:,('sex', 'chest_pain_type', 'fasting_blood_sugar', 'rest_ecg', 'exer_ind_angina', 'st_slope', 'num_major_vessels', 'thallium_scint')]\n",
    "\n",
    "X_train_con, X_test_con, y_train_con, y_test_con = train_test_split(X_con, y, random_state=0)\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, y, random_state=0)\n",
    "\n",
    "log_reg = sm.Logit(y_train_con, X_train_con)\n",
    "log_result = log_reg.fit()\n",
    "\n",
    "print(log_result.summary2())\n",
    "features_con = np.array(names_con)\n",
    "plot_feature_importance_log(fit = log_result, features = features_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis it can be seen that the only variables of significance are max_heart_rate and st_depression.\n",
    "The remainder of the variables will be rejected based on their coefficient sizes.\n",
    "\n",
    "Now we perform a univariate comparison between all the features. We use the mlxtend library for this. We fit a\n",
    "Logistic regression model to each variable in turn and study the accuracy obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logval = LogisticRegression(fit_intercept = False)\n",
    "\n",
    "efs1 = EFS(logval,\n",
    "           min_features=1,\n",
    "           max_features=1,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=5)\n",
    "\n",
    "efs1 = efs1.fit(X_train, y_train, custom_feature_names=feature_names)\n",
    "\n",
    "print('Best accuracy score: %.2f' % efs1.best_score_)\n",
    "print('Best subset (indices):', efs1.best_idx_)\n",
    "print('Best subset (corresponding names):', efs1.best_feature_names_)\n",
    "\n",
    "#efs1 = efs1.fit(X, y, custom_feature_names=feature_names)\n",
    "\n",
    "df_efs = pd.DataFrame.from_dict(efs1.get_metric_dict()).T\n",
    "df_efs.sort_values('avg_score', inplace=True, ascending=False)\n",
    "\n",
    "metric_dict = efs1.get_metric_dict()\n",
    "\n",
    "fig = plt.figure()\n",
    "k_feat = sorted(metric_dict.keys())\n",
    "avg = [metric_dict[k]['avg_score'] for k in k_feat]\n",
    "\n",
    "upper, lower = [], []\n",
    "for k in k_feat:\n",
    "    upper.append(metric_dict[k]['avg_score'] +\n",
    "                 metric_dict[k]['std_dev'])\n",
    "    lower.append(metric_dict[k]['avg_score'] -\n",
    "                 metric_dict[k]['std_dev'])\n",
    "\n",
    "plt.fill_between(k_feat,\n",
    "                 upper,\n",
    "                 lower,\n",
    "                 alpha=0.2,\n",
    "                 color='blue',\n",
    "                 lw=1)\n",
    "\n",
    "_ = plt.plot(k_feat, avg, color='blue', marker='o');\n",
    "_ = plt.ylabel('Accuracy +/- Standard Deviation', size = 15)\n",
    "_ = plt.xlabel('Feature', size = 15)\n",
    "feature_min = len(metric_dict[k_feat[0]]['feature_idx'])\n",
    "feature_max = len(metric_dict[k_feat[-1]]['feature_idx'])\n",
    "_ = plt.xticks(k_feat,\n",
    "           [str(metric_dict[k]['feature_names']) for k in k_feat],\n",
    "           rotation=90, size = 15)\n",
    "_ = plt.yticks(size = 15)\n",
    "plt.show();\n",
    "\n",
    "df_efs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis we can see that there are a large number of very strong predictors in this set of variables.\n",
    "thallium_scint scores 77% for accuracy and has the smallest confidence interval. exer_ind_angina and num_major_vessels\n",
    "similarly have high accuracy and small confidence intervals. chest_pain_type and max_heart_rate also have very high\n",
    "accuracy scores.\n",
    "\n",
    "Next we will however make use of scikit-learn's native feature extraction methods - which also allow for Univariate\n",
    "tests. The Uni-variate Anova test on continuous variables as implemented in SelectKBest function 'f_classif' will\n",
    "be used. Let's see what the results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Feature extraction set to retain all - we want to see scores for all variables.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m test \u001B[38;5;241m=\u001B[39m SelectKBest(score_func\u001B[38;5;241m=\u001B[39mf_classif, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m fit_kbest \u001B[38;5;241m=\u001B[39m test\u001B[38;5;241m.\u001B[39mfit(\u001B[43mX_train_con\u001B[49m, y_train_con)\n\u001B[1;32m      4\u001B[0m features_kbest \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(X_con\u001B[38;5;241m.\u001B[39mcolumns)\n\u001B[1;32m      5\u001B[0m plot_feature_importance(fit \u001B[38;5;241m=\u001B[39m fit_kbest, features \u001B[38;5;241m=\u001B[39m features_kbest)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_con' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature extraction set to retain all - we want to see scores for all variables.\n",
    "test = SelectKBest(score_func=f_classif, k=5)\n",
    "fit_kbest = test.fit(X_train_con, y_train_con)\n",
    "features_kbest = np.array(X_con.columns)\n",
    "plot_feature_importance(fit = fit_kbest, features = features_kbest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is notable in this analysis is the fact that age shows a higher significance here than for the previous test.\n",
    "This is due to the fact that age and max_heart_rate are cross-correlated as seen from Pearson's cross correlation test -\n",
    "reported a bit later in this document. The strong correlation between max_heart_rate and ca_disease diminishes the\n",
    "impact of age in multivariate tests. Univariate tests are better suited to this analysis for this reason.\n",
    "\n",
    "Although age does clearly have value as a variable, and in general it is good to include in any healthcare regression\n",
    "analysis due to the insights it brings, we will exclude it based on test results and levels of significance of other\n",
    "variables being much greater and capturing the effect of age sufficiently. We later discuss a strategy for the inclusion\n",
    "of age at a later stage.\n",
    "\n",
    "We will now consider the categorical variables. Again the SelectKBest method will be used again, but this time the\n",
    "Chi-Squared function 'chi2' for categorical variables will be used. Let's see what the results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = SelectKBest(score_func=chi2, k='all')\n",
    "fit_kbest_cat = test_cat.fit(X_train_cat, y_train_cat)\n",
    "features_kbest_cat = np.array(X_cat.columns)\n",
    "plot_feature_importance(fit = fit_kbest_cat, features = features_kbest_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_major_vessels, thal_scint and exer_ind_angina are all extremely strong predictors. chest_pain_type, st_slope and\n",
    "sex also contribute to the overall classification. From this analysis the only non-significant variables are\n",
    "rest_ecg and fasting_blood_sugar.\n",
    "\n",
    "We have now analysed continuous at categorical data separately from a statistical perspective.\n",
    "Before we make the final decision on what variables to drop, we will now consider an ML technique for deriving feature\n",
    "importance i.e. Decision Trees and Random Forests. Unlike the case of regression, we can analyse and draw conclusions\n",
    "on continuous and categorical data together when using these algorithms as they are impervious to differences in\n",
    "variable type. Another nice feature about Trees is that we don't have to standardise and normalise features which\n",
    "makes visual analysis a lot more intuitive. We therefore use our initial untransformed dataset for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Decision Tree to data - perform cross validation to obtain optimum value for hyperparameter used for pruning.\n",
    "samples = [sample for sample in range(1,30)]\n",
    "validation_scores = []\n",
    "for sample in samples:\n",
    "    classifier1 = DecisionTreeClassifier(random_state=1, min_samples_leaf=sample)\n",
    "    score = cross_val_score(estimator=classifier1, X=X_train_rf, y=y_train_rf, cv=5)\n",
    "    validation_scores.append(score.mean())\n",
    "\n",
    "# Obtain the minimum leaf samples with the highest validation score\n",
    "samples_optimum = samples[validation_scores.index(max(validation_scores))]\n",
    "\n",
    "# Create final classifier\n",
    "classifier2 = DecisionTreeClassifier(random_state=0, min_samples_leaf=samples_optimum)\n",
    "classifier2 = classifier2.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# Probability scores for test set\n",
    "y_pred_rf = classifier2.predict(X_test_rf)\n",
    "\n",
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test_rf, y_pred_rf)\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_pred_rf, y_test_rf)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = np.array(classifier2.feature_importances_)\n",
    "feature_list = np.array(X.columns)\n",
    "plot_feature_importance_dec(fit = importances, features = feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few levels of the tree\n",
    "_ = export_graphviz(classifier2, out_file='tree.dot',\n",
    "                feature_names = X.columns,\n",
    "                class_names = ['No CAD', 'CAD'],\n",
    "                rounded = True, proportion = True,\n",
    "                label='root',\n",
    "                precision = 2, filled = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has accuracy below 70% (ROC curve slope flatter than models thus far) and the feature importance results\n",
    "are not very convincing seeing as many values are missing. This model needs a bit more work. Interesting to note\n",
    "that Thallium Scintograpy comes out very strongly even in this sub-optimal model.\n",
    "We will next look at random forests to see if we can improve on the single tree's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(max_features=0.25, n_estimators=1000, criterion= 'gini',\n",
    "                                     random_state=0)\n",
    "rand_forest.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# Probability scores for test set\n",
    "y_pred_rf = rand_forest.predict(X_test_rf)\n",
    "\n",
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test_rf, y_pred_rf)\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_pred_rf, y_test_rf)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = np.array(rand_forest.feature_importances_)\n",
    "feature_list = np.array(X.columns)\n",
    "plot_feature_importance_dec(fit = importances, features = feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = rand_forest.estimators_[1]\n",
    "\n",
    "# Show the first few levels of the tree\n",
    "_ = export_graphviz(estimator, out_file='tree.dot',\n",
    "                feature_names = X.columns,\n",
    "                class_names = ['No CAD', 'CAD'],\n",
    "                rounded = True, proportion = True,\n",
    "                label='root',\n",
    "                precision = 2, filled = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest plot is interesting to analyse. Visually one can observe that ca disease (blue nodes) is evenly\n",
    "spread throughout the leave nodes of the entire tree. A large proportion of the early ca disease nodes occur for\n",
    "individuals with maximum heart rate < 150 and cholesterol >210. From here if ST depression >0.8 and one is male around\n",
    "20% of the overall population is classified as having ca disease.\n",
    "Likewise, a large proportion of the population with max heart rate >150 and chest pain < 3.5 is classified as not\n",
    "having ca disease (orange nodes).\n",
    "Another interesting factor is that Thallium Scintography is reported as the second most important feature. It does \n",
    "however not feature strongly in the Decision Tree. It is likely that strong cross-correlation with other strong \n",
    "features such as maximum heart rate causes the Thallium feature to only surface as a confirmatory feature at lower \n",
    "levels in the tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build our final Logistic Regression model with the variables selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_fin_cat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Extract continuous and categorical variables for analysis.\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m X_fin_cat \u001B[38;5;241m=\u001B[39m \u001B[43mdf_fin_cat\u001B[49m\u001B[38;5;241m.\u001B[39mloc[:,(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msex\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchest_pain_type\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexer_ind_angina\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mst_slope\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_major_vessels\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthallium_scint\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m      3\u001B[0m X_fin_con \u001B[38;5;241m=\u001B[39m df_fin_con\u001B[38;5;241m.\u001B[39mloc[:,(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_heart_rate\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mst_depression\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m      4\u001B[0m X_final \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat([X_fin_cat, X_fin_con], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df_fin_cat' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract continuous and categorical variables for analysis.\n",
    "X_fin_cat = df_fin_cat.loc[:,('sex', 'chest_pain_type', 'exer_ind_angina', 'st_slope', 'num_major_vessels', 'thallium_scint')]\n",
    "X_fin_con = df_fin_con.loc[:,('max_heart_rate', 'st_depression')]\n",
    "X_final = pd.concat([X_fin_cat, X_fin_con], axis=1)\n",
    "\n",
    "X_train_fin, X_test_fin, y_train_fin, y_test_fin = train_test_split(X_final, y, random_state=0)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data set\n",
    "scaler.fit(X_train_fin)\n",
    "X_train_fin = scaler.transform(X_train_fin)\n",
    "\n",
    "# Apply to test data\n",
    "X_test_fin = scaler.transform(X_test_fin)\n",
    "\n",
    "# Final model\n",
    "logfin = LogisticRegression(fit_intercept = False)\n",
    "\n",
    "# Probability scores for test set\n",
    "y_score_fin = logfin.fit(X_train_fin, y_train_fin).decision_function(X_test_fin)\n",
    "\n",
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test_fin, y_score_fin)\n",
    "\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fin = logfin.predict(X_test_fin)\n",
    "# Accuracy before model parameter optimisation\n",
    "cnf_matrix = confusion_matrix(y_pred_fin, y_test_fin)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy results indicate that even though 5 variables were dropped, the model accuracy did not reduce by\n",
    "a significant amount. We can therefore confidently deploy this model with the knowledge that it is both robust and\n",
    "accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Build Model 2 - Multi-Layer Perceptron</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build a Multi Layer Perceptron to compare with the Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE before model optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and check MSE before regularisation\n",
    "reg = MLPClassifier(max_iter=50000, solver=\"adam\", activation=\"tanh\", hidden_layer_sizes=(5, 5), random_state=1)\n",
    "reg.fit(X_train_fin, y_train_fin)\n",
    "\n",
    "# Predict\n",
    "y_pred_fin = reg.predict(X_test_fin)\n",
    "\n",
    "# Accuracy before model parameter optimisation\n",
    "accuracy_score(y_pred_fin, y_test_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now optimise the NN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes |Validation\n",
      "      | score\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_fin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hidden_layer_size \u001B[38;5;129;01min\u001B[39;00m [(i,j) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m6\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m6\u001B[39m)]:\n\u001B[1;32m      8\u001B[0m     reg \u001B[38;5;241m=\u001B[39m MLPClassifier(max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000000\u001B[39m, hidden_layer_sizes\u001B[38;5;241m=\u001B[39mhidden_layer_size, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m     score \u001B[38;5;241m=\u001B[39m cross_val_score(estimator\u001B[38;5;241m=\u001B[39mreg, X\u001B[38;5;241m=\u001B[39m\u001B[43mX_train_fin\u001B[49m, y\u001B[38;5;241m=\u001B[39my_train_fin, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     11\u001B[0m     validation_scores[hidden_layer_size] \u001B[38;5;241m=\u001B[39m score\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;28mprint\u001B[39m(hidden_layer_size, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m%0.5f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m validation_scores[hidden_layer_size])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_train_fin' is not defined"
     ]
    }
   ],
   "source": [
    "# Optimise numbers of nodes on both layers\n",
    "validation_scores = {}\n",
    "print(\"Nodes |Validation\")\n",
    "print(\"      | score\")\n",
    "\n",
    "for hidden_layer_size in [(i,j) for i in range(3,6) for j in range(3,6)]:\n",
    "\n",
    "    reg = MLPClassifier(max_iter=1000000, hidden_layer_sizes=hidden_layer_size, random_state=1)\n",
    "\n",
    "    score = cross_val_score(estimator=reg, X=X_train_fin, y=y_train_fin, cv=2)\n",
    "    validation_scores[hidden_layer_size] = score.mean()\n",
    "    print(hidden_layer_size, \": %0.5f\" % validation_scores[hidden_layer_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check scores\n",
    "print(\"The highest validation score is: %0.4f\" % max(validation_scores.values()))\n",
    "optimal_hidden_layer_size = [name for name, score in validation_scores.items()\n",
    "                              if score==max(validation_scores.values())][0]\n",
    "print(\"This corresponds to nodes\", optimal_hidden_layer_size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimise neural network regularisation parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select range over which to find regularisation parameter - exponential used for even distribution of values\n",
    "reg_par = [np.e**n for n in np.arange(-2,4,0.5)]\n",
    "\n",
    "validation_scores = {}\n",
    "print(\" alpha  |  Accuracy\")\n",
    "for param in reg_par:\n",
    "    reg = MLPClassifier(max_iter=1000000, solver=\"adam\", activation=\"tanh\", hidden_layer_sizes=optimal_hidden_layer_size, alpha=param,\n",
    "                        random_state=1)\n",
    "    score = cross_val_score(estimator=reg, X=X_train_fin, y=y_train_fin, cv=2, scoring=\"accuracy\")\n",
    "    validation_scores[param] = score.mean()\n",
    "    print(\"%0.5f |  %s\" % (param, score.mean()))\n",
    "\n",
    "# Plot the accuracy function against regularisation parameter\n",
    "plt.plot([np.log(i) for i in validation_scores.keys()], list(validation_scores.values()));\n",
    "plt.xlabel(\"Ln of alpha\");\n",
    "plt.ylabel(\"Accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest cross-validation accuracy score and hence the value to use for the `alpha` parameter is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = ([np.log(name) for name, score in validation_scores.items() if score==max(validation_scores.values())][0])\n",
    "\n",
    "# Find lowest value.\n",
    "print(\"The highest accuracy score is: %s\" % (max(validation_scores.values())))\n",
    "print(\"This corresponds to regularisation parameter e**%s\" % max_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE after regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data with the best parameter\n",
    "reg = MLPClassifier(max_iter=1000000, solver=\"adam\", activation=\"tanh\", hidden_layer_sizes=optimal_hidden_layer_size,\n",
    "                    alpha=np.e**(2), random_state=1)\n",
    "\n",
    "reg.fit(X_train_fin, y_train_fin)\n",
    "\n",
    "# Predict\n",
    "y_pred = reg.predict(X_test_fin)\n",
    "\n",
    "# Accuracy after model parameter optimisation\n",
    "accuracy_score(y_pred_fin, y_test_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Analysis of results</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot response curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create X_design_vec, which contains the median of each respective column\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m X_design \u001B[38;5;241m=\u001B[39m \u001B[43mX_final\u001B[49m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m      3\u001B[0m X_design_vec \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(X_design\u001B[38;5;241m.\u001B[39mmedian())\u001B[38;5;241m.\u001B[39mtranspose()\n\u001B[1;32m      4\u001B[0m X_design_vec\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_final' is not defined"
     ]
    }
   ],
   "source": [
    "# Create X_design_vec, which contains the median of each respective column\n",
    "X_design = X_final.copy()\n",
    "X_design_vec = pd.DataFrame(X_design.median()).transpose()\n",
    "X_design_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_num = ('sex', 'chest_pain_type', 'max_heart_rate', 'exer_ind_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thallium_scint')\n",
    "\n",
    "for variable in names_num:\n",
    "    # Set up a sequence for response variable to plot\n",
    "    min_res = min(X.loc[:,variable])\n",
    "    max_res = max(X.loc[:,variable])\n",
    "    seq = np.linspace(start=min_res,stop=max_res,num=50)\n",
    "\n",
    "    # Set up a list of moving resultants to plot\n",
    "    to_predict = []\n",
    "    for result in seq:\n",
    "        X_design_vec.loc[0,variable] = result\n",
    "        to_predict.append(X_design_vec.copy())\n",
    "\n",
    "    # Convert back to dataframe\n",
    "    to_predict = pd.concat(to_predict)\n",
    "\n",
    "    # Scale and predict\n",
    "    to_predict = scaler.transform(to_predict)\n",
    "    predictions = reg.predict_proba(to_predict)\n",
    "\n",
    "    # Plot\n",
    "    _ = plt.plot(seq,predictions[:,1])\n",
    "    _ = plt.xlabel(variable)\n",
    "    _ = plt.ylabel(\"ca_disease\")\n",
    "    _ = plt.title(\"ca_disease vs \" + variable)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is accurate enough to capture the directly proportionate relationship between several response variables\n",
    "(in order of strength of association, based on response curve output):\n",
    "\n",
    "- thallium_scint\n",
    "- num_major_vessels\n",
    "- st_slope\n",
    "- st_depression\n",
    "- exer_ind_angina\n",
    "- chest_pain_type\n",
    "- sex\n",
    "\n",
    "and the inversely proportional relationship between:\n",
    "\n",
    "- max_heart_rate\n",
    "\n",
    "and the outcome of confirmed Coronary Artery Disease. This is a positive outcome, as it means the model as applied\n",
    "to the validation dataset managed to capture the underlying signals in the data. We can therefore conclude that the\n",
    "model generalises well and that its accuracy is sufficiently high for this model to be used based on the features\n",
    "captured.\n",
    "\n",
    "This makes sense if one takes into account that the first two variables:\n",
    "\n",
    "- thallium_scint: Arteries found to be: 1. Normal 2. Reversible defect and 3. Fixed defect\n",
    "- num_major_vessels: Number of major vessels (0-3) coloured by fluoroscopy\n",
    "\n",
    "are by nature close to the definition of Coronary Artery Disease itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False positive Rate and true positive rate\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_pred)\n",
    "plot_roc_curve(fpr = fpr_roc, tpr = tpr_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_pred, y_test)\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1], normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the similar levels of accuracy that both the Logistic and MLP models attained it will be up to clinical decision\n",
    "makers to decide on the utility of these approaches. Given the confidence in the Gold Standard i.e. Angiography and the\n",
    "consequences of incorrect diagnosis, in my mind it is unlikely that a test resulting in a sensitivity of approximately 90% or less will be considered as a replacement.\n",
    "An understanding of the factors contributing to a positive Angiogram test would however assist clinicians in deciding\n",
    "when an Angiogram might be indicated and what the likely outcome would be. This could assist in early intervention,\n",
    "workup and planning. As I understand it there are problems in some settings with too many Angiograms being performed which could result in poorer patient care and outcomes. \n",
    "This analysis identified the 8 most important features to consider which are: thallium_scint, num_major_vessels,\n",
    "st_slope, st_depression, max_heart_rate, exer_ind_angina, chest_pain_type and sex.\n",
    "\n",
    "The Decision Tree provides useful information as a starting point for a discussion on an algorithm to decide whether\n",
    "an Angiogram is indicated for a particular patient. Further analytic work to assist with such a discussion could be to\n",
    "investigate cut-off points for different age/ sex groups or for populations with different prevalence of disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
